{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "cleaned_books_df = pd.read_csv(\"../data/extended_books_google_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop embedding column\n",
    "# cleaned_books_df = cleaned_books_df.drop(columns=[\"full_text_embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop description fulltext title\n",
    "cleaned_books_df = cleaned_books_df.drop(\n",
    "    columns=[\"description\", \"title\", \"full_text\", \"subtitle\", \"maturityRating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year from publisheDate\n",
    "cleaned_books_df[\"publishedDate\"] = cleaned_books_df[\"publishedDate\"].str.extract(\n",
    "    r\"(\\d{4})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"authors\",\n",
    "    \"publisher\",\n",
    "    \"language\",\n",
    "    \"categories\",\n",
    "    \"publishedDate\",\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    cleaned_books_df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "multi_valued_columns = [\"categories\", \"authors\"]\n",
    "\n",
    "for (\n",
    "    col\n",
    ") in (\n",
    "    multi_valued_columns\n",
    "):  # convert to a single number 1 number in the column not a list\n",
    "    le = LabelEncoder()\n",
    "    cleaned_books_df[col] = le.fit_transform(cleaned_books_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to numeric\n",
    "# cleaned_books_df[\"publisher\"] = pd.to_numeric(cleaned_books_df[\"publisher\"], errors=\"coerce\")\n",
    "# cleaned_books_df[\"language\"] = pd.to_numeric(cleaned_books_df[\"language\"], errors=\"coerce\")\n",
    "\n",
    "# # fill missing for all columns\n",
    "# cleaned_books_df = cleaned_books_df.fillna(0)\n",
    "\n",
    "# # standardize\n",
    "# scaler = StandardScaler()\n",
    "# cleaned_books_df = pd.DataFrame(\n",
    "#     scaler.fit_transform(cleaned_books_df), columns=cleaned_books_df.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "train_df = train_df.merge(cleaned_books_df, on=\"book_id\", how=\"left\")\n",
    "test_df = test_df.merge(cleaned_books_df, on=\"book_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class BookRatingsDataset(Dataset):\n",
    "    def __init__(self, df, is_test=False):\n",
    "        self.is_test = is_test\n",
    "        self.book_ids = torch.tensor(df[\"book_id\"].values, dtype=torch.long)\n",
    "        self.user_ids = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.pageCounts = torch.tensor(df[\"pageCount\"].values, dtype=torch.float)\n",
    "        self.ratingsCount = torch.tensor(df[\"ratingsCount\"].values, dtype=torch.float)\n",
    "        self.averageRating = torch.tensor(df[\"averageRating\"].values, dtype=torch.float)\n",
    "        self.publishDate = torch.tensor(df[\"publishedDate\"].values, dtype=torch.long)\n",
    "\n",
    "        # Multi-valued features stored as numpy arrays\n",
    "        self.categories = df[\"categories\"].values\n",
    "        self.authors = df[\"authors\"].values\n",
    "\n",
    "        if not is_test:\n",
    "            self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.book_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        book_id = self.book_ids[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "        pages = self.pageCounts[idx]\n",
    "        ratings = self.ratingsCount[idx]\n",
    "        average_rating = self.averageRating[idx]\n",
    "        publish_date = self.publishDate[idx]\n",
    "\n",
    "        categories = self.categories[idx]\n",
    "        authors = self.authors[idx]\n",
    "\n",
    "        if self.is_test:\n",
    "            return (\n",
    "                book_id,\n",
    "                user_id,\n",
    "                pages,\n",
    "                ratings,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                categories,\n",
    "                authors,\n",
    "            )\n",
    "        else:\n",
    "            rating = self.ratings[idx]\n",
    "            return (\n",
    "                book_id,\n",
    "                user_id,\n",
    "                pages,\n",
    "                ratings,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                categories,\n",
    "                authors,\n",
    "                rating,\n",
    "            )\n",
    "\n",
    "\n",
    "class BookRatingPredictor(nn.Module):\n",
    "    def __init__(self, n_books, n_users, n_genres, n_authors, embedding_size=50):\n",
    "        super(BookRatingPredictor, self).__init__()\n",
    "        self.book_embedding = nn.Embedding(n_books, embedding_size)\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_size)\n",
    "        self.genre_embedding = nn.Embedding(n_genres, embedding_size)\n",
    "        self.author_embedding = nn.Embedding(n_authors, embedding_size)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(embedding_size * 4 + 4, 128)  # Adjust input size\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        book_ids,\n",
    "        user_ids,\n",
    "        pages,\n",
    "        ratings_count,\n",
    "        average_rating,\n",
    "        publish_date,\n",
    "        genres,\n",
    "        authors,\n",
    "    ):\n",
    "        # Embeddings\n",
    "        book_embeds = self.book_embedding(book_ids)\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        genre_embeds = self.genre_embedding(genres)\n",
    "        author_embeds = self.author_embedding(authors)\n",
    "\n",
    "        pages = pages.unsqueeze(1)  # From shape [batch_size] to [batch_size, 1]\n",
    "        ratings_count = ratings_count.unsqueeze(1)\n",
    "        average_rating = average_rating.unsqueeze(1)\n",
    "        publish_date = publish_date.unsqueeze(1)\n",
    "\n",
    "        # Concatenate all features\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                book_embeds,\n",
    "                user_embeds,\n",
    "                genre_embeds,\n",
    "                author_embeds,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_book_id = train_df[\"book_id\"].max()\n",
    "max_user_id = train_df[\"user_id\"].max()\n",
    "num_genres = train_df[\"categories\"].max() + 1\n",
    "num_authors = train_df[\"authors\"].max() + 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = BookRatingPredictor(\n",
    "    max_book_id + 1, max_user_id + 1, num_genres, num_authors, embedding_size=50\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5, device=device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            # Unpack the data from the DataLoader\n",
    "            (\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                genres,\n",
    "                authors,\n",
    "                ratings,\n",
    "            ) = data\n",
    "\n",
    "            # Move tensors to the appropriate device\n",
    "            book_ids = book_ids.to(device)\n",
    "            user_ids = user_ids.to(device)\n",
    "            pages = pages.to(device)\n",
    "            ratings_count = ratings_count.to(device)\n",
    "            average_rating = average_rating.to(device)\n",
    "            publish_date = publish_date.to(device)\n",
    "            genres = genres.to(device)\n",
    "            authors = authors.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero out the gradients\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                genres,\n",
    "                authors,\n",
    "            )\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, ratings)\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Compute and print RMSE for the epoch\n",
    "        rmse = torch.sqrt(torch.tensor(total_loss / len(train_loader))).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BookRatingsDataset(train_df)\n",
    "test_dataset = BookRatingsDataset(test_df, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for data in test_loader:\n",
    "            (\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                genres,\n",
    "                authors,\n",
    "                publishers,\n",
    "                languages,\n",
    "                publish_dates,\n",
    "            ) = data\n",
    "            # Move data to the appropriate device\n",
    "            book_ids, user_ids, pages = (\n",
    "                book_ids.to(device),\n",
    "                user_ids.to(device),\n",
    "                pages.to(device),\n",
    "            )\n",
    "            genres, authors = genres.to(device), authors.to(device)\n",
    "            publishers, languages = publishers.to(device), languages.to(device)\n",
    "            publish_dates = publish_dates.to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                genres,\n",
    "                authors,\n",
    "                publishers,\n",
    "                languages,\n",
    "                publish_dates,\n",
    "            )\n",
    "            predictions.extend(\n",
    "                outputs.cpu().numpy()\n",
    "            )  # Move predictions to CPU and convert to numpy array\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Prepare the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicitons to csv file in the format\n",
    "# id,rating\n",
    "test_df[\"rating\"] = predictions\n",
    "test_df[[\"id\", \"rating\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import (\n",
    "    Dataset,\n",
    "    Reader,\n",
    "    SVD,\n",
    "    KNNBasic,\n",
    "    KNNWithMeans,\n",
    "    KNNWithZScore,\n",
    "    KNNBaseline,\n",
    "    NMF,\n",
    "    SlopeOne,\n",
    "    CoClustering,\n",
    "    BaselineOnly,\n",
    "    NormalPredictor,\n",
    ")\n",
    "from surprise.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "# List of models to test\n",
    "models = [\n",
    "    (\"SVD\", SVD()),\n",
    "    (\"KNNBasic\", KNNBasic()),\n",
    "    (\"KNNWithZScore\", KNNWithZScore()),\n",
    "    (\"KNNBaseline\", KNNBaseline()),\n",
    "    (\"NMF\", NMF()),\n",
    "    (\"SlopeOne\", SlopeOne()),\n",
    "    (\"CoClustering\", CoClustering()),\n",
    "    (\"BaselineOnly\", BaselineOnly()),\n",
    "    (\"NormalPredictor\", NormalPredictor()),\n",
    "]\n",
    "\n",
    "# Prepare the data\n",
    "reader = Reader(rating_scale=(train_df[\"rating\"].min(), train_df[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(train_df[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
    "\n",
    "# Iterate over models and cross-validate\n",
    "results = []\n",
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, data, measures=[\"RMSE\"], cv=5, verbose=True)\n",
    "    mean_rmse = cv_results[\"test_rmse\"].mean()\n",
    "    results.append((name, mean_rmse))\n",
    "\n",
    "# Sort models by RMSE\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Display the results\n",
    "for name, rmse in results:\n",
    "    print(f\"{name}: RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
