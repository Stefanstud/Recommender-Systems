{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "cleaned_books_df = pd.read_csv(\"../data/extended_books_google_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop embedding column\n",
    "# cleaned_books_df = cleaned_books_df.drop(columns=[\"full_text_embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gina Bari Kolata'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_books_df[\"authors\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan with empty string\n",
    "cleaned_books_df[\"categories\"] = cleaned_books_df[\"authors\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "                             3664\n",
       "Stephen King                  159\n",
       "Nora Roberts                  113\n",
       "Danielle Steel                 94\n",
       "John Grisham                   68\n",
       "                             ... \n",
       "Kerrelyn Sparks                 1\n",
       "Tom Holland                     1\n",
       "Jenny Downham                   1\n",
       "Esi Edugyan                     1\n",
       "Gilles NÃ©ret,Gustav Klimt       1\n",
       "Name: count, Length: 4323, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_books_df[\"categories\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with empty string\n",
    "cleaned_books_df[\"categories\"] = cleaned_books_df[\"categories\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publisher\n",
       "Penguin                           775\n",
       "Harper Collins                    539\n",
       "Macmillan                         484\n",
       "Bantam                            459\n",
       "Simon and Schuster                441\n",
       "                                 ... \n",
       "HarpPerenM                          1\n",
       "Folio                               1\n",
       "New York : Toronto : Doubleday      1\n",
       "U of Nebraska Press                 1\n",
       "Spectra Books                       1\n",
       "Name: count, Length: 986, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_books_df[\"publisher\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94399"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"user_id\"].value_counts().keys().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with empty string\n",
    "cleaned_books_df[\"publisher\"] = cleaned_books_df[\"publisher\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the max length of a list in author column\n",
    "max_len = max(cleaned_books_df[\"publisher\"].apply(lambda x: len(x.split(\",\"))))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop description fulltext title\n",
    "cleaned_books_df = cleaned_books_df.drop(\n",
    "    columns=[\"description\", \"title\", \"full_text\", \"subtitle\", \"maturityRating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year from publisheDate\n",
    "cleaned_books_df[\"publishedDate\"] = cleaned_books_df[\"publishedDate\"].str.extract(\n",
    "    r\"(\\d{4})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22563/3300455302.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_books_df[\"publishedDate\"].fillna(\n",
      "/tmp/ipykernel_22563/3300455302.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_books_df[col].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\n",
    "    \"authors\",\n",
    "    \"publisher\",\n",
    "    \"language\",\n",
    "    \"categories\",\n",
    "]\n",
    "\n",
    "# impute publishDate with most common\n",
    "cleaned_books_df[\"publishedDate\"].fillna(\n",
    "    cleaned_books_df[\"publishedDate\"].mode()[0], inplace=True\n",
    ")\n",
    "\n",
    "# convert it to int\n",
    "cleaned_books_df[\"publishedDate\"] = cleaned_books_df[\"publishedDate\"].astype(int)\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    cleaned_books_df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "multi_valued_columns = [\"categories\", \"authors\"]\n",
    "\n",
    "for (\n",
    "    col\n",
    ") in (\n",
    "    multi_valued_columns\n",
    "):  # convert to a single number 1 number in the column not a list\n",
    "    le = LabelEncoder()\n",
    "    cleaned_books_df[col] = le.fit_transform(cleaned_books_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22563/144752641.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_books_df[\"ratingsCount\"].fillna(\n",
      "/tmp/ipykernel_22563/144752641.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_books_df[\"averageRating\"].fillna(\n",
      "/tmp/ipykernel_22563/144752641.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_books_df[\"pageCount\"].fillna(\n"
     ]
    }
   ],
   "source": [
    "# impute numeric columns with mean ratingsCount averageRating pageCount\n",
    "\n",
    "cleaned_books_df[\"ratingsCount\"].fillna(\n",
    "    cleaned_books_df[\"ratingsCount\"].mean(), inplace=True\n",
    ")\n",
    "\n",
    "cleaned_books_df[\"averageRating\"].fillna(\n",
    "    cleaned_books_df[\"averageRating\"].mean(), inplace=True\n",
    ")\n",
    "\n",
    "cleaned_books_df[\"pageCount\"].fillna(cleaned_books_df[\"pageCount\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to numeric\n",
    "# cleaned_books_df[\"publisher\"] = pd.to_numeric(cleaned_books_df[\"publisher\"], errors=\"coerce\")\n",
    "# cleaned_books_df[\"language\"] = pd.to_numeric(cleaned_books_df[\"language\"], errors=\"coerce\")\n",
    "\n",
    "# # fill missing for all columns\n",
    "# cleaned_books_df = cleaned_books_df.fillna(0)\n",
    "\n",
    "# # standardize\n",
    "# scaler = StandardScaler()\n",
    "# cleaned_books_df = pd.DataFrame(\n",
    "#     scaler.fit_transform(cleaned_books_df), columns=cleaned_books_df.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "train_df = train_df.merge(cleaned_books_df, on=\"book_id\", how=\"left\")\n",
    "test_df = test_df.merge(cleaned_books_df, on=\"book_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class BookRatingsDataset(Dataset):\n",
    "    def __init__(self, df, is_test=False):\n",
    "        self.is_test = is_test\n",
    "        self.book_ids = torch.tensor(df[\"book_id\"].values, dtype=torch.long)\n",
    "        self.user_ids = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
    "        self.pageCounts = torch.tensor(df[\"pageCount\"].values, dtype=torch.float)\n",
    "        self.ratingsCount = torch.tensor(df[\"ratingsCount\"].values, dtype=torch.float)\n",
    "        self.averageRating = torch.tensor(df[\"averageRating\"].values, dtype=torch.float)\n",
    "        # convert from str to int\n",
    "        self.publishDate = torch.tensor(df[\"publishedDate\"].values, dtype=torch.float)\n",
    "\n",
    "        # Multi-valued features stored as numpy arrays\n",
    "        self.categories = df[\"categories\"].values\n",
    "        self.authors = df[\"authors\"].values\n",
    "\n",
    "        if not is_test:\n",
    "            self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.book_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        book_id = self.book_ids[idx]\n",
    "        user_id = self.user_ids[idx]\n",
    "        pages = self.pageCounts[idx]\n",
    "        ratings = self.ratingsCount[idx]\n",
    "        average_rating = self.averageRating[idx]\n",
    "        publish_date = self.publishDate[idx]\n",
    "\n",
    "        categories = self.categories[idx]\n",
    "        authors = self.authors[idx]\n",
    "\n",
    "        if self.is_test:\n",
    "            return (\n",
    "                book_id,\n",
    "                user_id,\n",
    "                pages,\n",
    "                ratings,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                categories,\n",
    "                authors,\n",
    "            )\n",
    "        else:\n",
    "            rating = self.ratings[idx]\n",
    "            return (\n",
    "                book_id,\n",
    "                user_id,\n",
    "                pages,\n",
    "                ratings,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                categories,\n",
    "                authors,\n",
    "                rating,\n",
    "            )\n",
    "\n",
    "\n",
    "class BookRatingPredictor(nn.Module):\n",
    "    def __init__(self, n_books, n_users, n_genres, n_authors, embedding_size=50):\n",
    "        super(BookRatingPredictor, self).__init__()\n",
    "        self.book_embedding = nn.Embedding(n_books, embedding_size)\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_size)\n",
    "        self.genre_embedding = nn.Embedding(n_genres, embedding_size)\n",
    "        self.author_embedding = nn.Embedding(n_authors, embedding_size)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(embedding_size * 4 + 4, 128)  # Adjust input size\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        book_ids,\n",
    "        user_ids,\n",
    "        pages,\n",
    "        ratings_count,\n",
    "        average_rating,\n",
    "        publish_date,\n",
    "        genres,\n",
    "        authors,\n",
    "    ):\n",
    "        # Embeddings\n",
    "        book_embeds = self.book_embedding(book_ids)\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        genre_embeds = self.genre_embedding(genres)\n",
    "        author_embeds = self.author_embedding(authors)\n",
    "\n",
    "        pages = pages.unsqueeze(1)  # From shape [batch_size] to [batch_size, 1]\n",
    "        ratings_count = ratings_count.unsqueeze(1)\n",
    "        average_rating = average_rating.unsqueeze(1)\n",
    "        publish_date = publish_date.unsqueeze(1)\n",
    "\n",
    "        # Concatenate all features\n",
    "        x = torch.cat(\n",
    "            [\n",
    "                book_embeds,\n",
    "                user_embeds,\n",
    "                genre_embeds,\n",
    "                author_embeds,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BookRatingPredictor(\n",
       "  (book_embedding): Embedding(249243, 50)\n",
       "  (user_embedding): Embedding(94400, 50)\n",
       "  (genre_embedding): Embedding(972, 50)\n",
       "  (author_embedding): Embedding(4323, 50)\n",
       "  (fc1): Linear(in_features=204, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_book_id = train_df[\"book_id\"].max()\n",
    "max_user_id = train_df[\"user_id\"].max()\n",
    "num_genres = train_df[\"categories\"].max() + 1\n",
    "num_authors = train_df[\"authors\"].max() + 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = BookRatingPredictor(\n",
    "    max_book_id + 1, max_user_id + 1, num_genres, num_authors, embedding_size=50\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5, device=device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data in train_loader:\n",
    "            # Unpack the data from the DataLoader\n",
    "            (\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                genres,\n",
    "                authors,\n",
    "                ratings,\n",
    "            ) = data\n",
    "\n",
    "            # Move tensors to the appropriate device\n",
    "            book_ids = book_ids.to(device)\n",
    "            user_ids = user_ids.to(device)\n",
    "            pages = pages.to(device)\n",
    "            ratings_count = ratings_count.to(device)\n",
    "            average_rating = average_rating.to(device)\n",
    "            publish_date = publish_date.to(device)\n",
    "            genres = genres.to(device)\n",
    "            authors = authors.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero out the gradients\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                ratings_count,\n",
    "                average_rating,\n",
    "                publish_date,\n",
    "                genres,\n",
    "                authors,\n",
    "            )\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, ratings)\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Compute and print RMSE for the epoch\n",
    "        rmse = torch.sqrt(torch.tensor(total_loss / len(train_loader))).item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BookRatingsDataset(train_df)\n",
    "test_dataset = BookRatingsDataset(test_df, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/29], Loss: 2055.391490340233, RMSE: 1.6170967817306519\n",
      "Epoch [2/29], Loss: 1007.1771611571312, RMSE: 1.1319875717163086\n",
      "Epoch [3/29], Loss: 830.8409435153008, RMSE: 1.0281291007995605\n",
      "Epoch [4/29], Loss: 652.6757103204727, RMSE: 0.9112498164176941\n",
      "Epoch [5/29], Loss: 555.1399901211262, RMSE: 0.8404076099395752\n",
      "Epoch [6/29], Loss: 498.9832522571087, RMSE: 0.7967677116394043\n",
      "Epoch [7/29], Loss: 454.11483454704285, RMSE: 0.7601014971733093\n",
      "Epoch [8/29], Loss: 422.8504247367382, RMSE: 0.7334696054458618\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 56\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 56\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Compute and print RMSE for the epoch\u001b[39;00m\n\u001b[1;32m     59\u001b[0m rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mtensor(total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)))\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for data in test_loader:\n",
    "            (\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                genres,\n",
    "                authors,\n",
    "                publishers,\n",
    "                languages,\n",
    "                publish_dates,\n",
    "            ) = data\n",
    "            # Move data to the appropriate device\n",
    "            book_ids, user_ids, pages = (\n",
    "                book_ids.to(device),\n",
    "                user_ids.to(device),\n",
    "                pages.to(device),\n",
    "            )\n",
    "            genres, authors = genres.to(device), authors.to(device)\n",
    "            publishers, languages = publishers.to(device), languages.to(device)\n",
    "            publish_dates = publish_dates.to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                book_ids,\n",
    "                user_ids,\n",
    "                pages,\n",
    "                genres,\n",
    "                authors,\n",
    "                publishers,\n",
    "                languages,\n",
    "                publish_dates,\n",
    "            )\n",
    "            predictions.extend(\n",
    "                outputs.cpu().numpy()\n",
    "            )  # Move predictions to CPU and convert to numpy array\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Prepare the test DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3357809,\n",
       " 1.2703103,\n",
       " 1.0420502,\n",
       " 1.7972617,\n",
       " 1.699336,\n",
       " 1.192356,\n",
       " 1.252356,\n",
       " 1.0769513,\n",
       " 2.7856808,\n",
       " 1.2738022,\n",
       " 1.310165,\n",
       " 1.5013684,\n",
       " 1.1455977,\n",
       " 1.2593044,\n",
       " 1.7285088,\n",
       " 1.2978414,\n",
       " 1.0803208,\n",
       " 1.1061174,\n",
       " 1.1733896,\n",
       " 1.8144957,\n",
       " 1.1902926,\n",
       " 4.23983,\n",
       " 2.1197567,\n",
       " 1.4649922,\n",
       " 1.031712,\n",
       " 1.1347464,\n",
       " 2.016117,\n",
       " 1.8081076,\n",
       " 1.4784185,\n",
       " 1.5264933,\n",
       " 1.4216475,\n",
       " 1.0130728,\n",
       " 2.0254185,\n",
       " 1.2532557,\n",
       " 1.3089827,\n",
       " 1.316214,\n",
       " 1.5891939,\n",
       " 2.5812736,\n",
       " 1.6110508,\n",
       " 0.91034603,\n",
       " 2.3699665,\n",
       " 0.93539375,\n",
       " 1.1965493,\n",
       " 1.8261071,\n",
       " 0.7601313,\n",
       " 1.6999717,\n",
       " 1.5765573,\n",
       " 1.3336707,\n",
       " 1.1921328,\n",
       " 1.188313,\n",
       " 0.9232527,\n",
       " 1.691069,\n",
       " 2.1097097,\n",
       " 0.94479734,\n",
       " 1.6309656,\n",
       " 2.3354034,\n",
       " 1.3194557,\n",
       " 1.4834102,\n",
       " 1.9687127,\n",
       " 1.5144086,\n",
       " 1.8064224,\n",
       " 1.1272494,\n",
       " 1.0132694,\n",
       " 3.1494503,\n",
       " 1.3902146,\n",
       " 1.7022454,\n",
       " 1.7392749,\n",
       " 1.1470248,\n",
       " 1.0024407,\n",
       " 1.5537982,\n",
       " 1.3734666,\n",
       " 1.2432529,\n",
       " 0.9533769,\n",
       " 1.309085,\n",
       " 1.2835637,\n",
       " 0.7563098,\n",
       " 2.0063636,\n",
       " 1.6071825,\n",
       " 1.3256527,\n",
       " 1.4435061,\n",
       " 1.2884718,\n",
       " 1.2306424,\n",
       " 1.599623,\n",
       " 1.5087966,\n",
       " 2.808608,\n",
       " 1.7113981,\n",
       " 1.3891337,\n",
       " 2.4659722,\n",
       " 1.2816399,\n",
       " 2.0888174,\n",
       " 1.306172,\n",
       " 1.2194158,\n",
       " 1.7114445,\n",
       " 1.2286421,\n",
       " 1.511245,\n",
       " 2.50205,\n",
       " 3.106966,\n",
       " 1.2065378,\n",
       " 2.0062623,\n",
       " 2.2006218,\n",
       " 1.4185814,\n",
       " 1.0824851,\n",
       " 1.1918943,\n",
       " 1.9211644,\n",
       " 1.898374,\n",
       " 1.8363954,\n",
       " 1.1337122,\n",
       " 1.1603997,\n",
       " 1.3202041,\n",
       " 1.2779026,\n",
       " 1.1583112,\n",
       " 1.0042844,\n",
       " 1.3274647,\n",
       " 1.1968467,\n",
       " 1.6918541,\n",
       " 1.474547,\n",
       " 1.1443074,\n",
       " 1.9333668,\n",
       " 1.7772453,\n",
       " 1.5812211,\n",
       " 1.4320241,\n",
       " 1.216988,\n",
       " 2.0981736,\n",
       " 1.1733277,\n",
       " 1.2854148,\n",
       " 1.3950278,\n",
       " 1.1937103,\n",
       " 2.310824,\n",
       " 1.9837881,\n",
       " 1.919746,\n",
       " 1.0154349,\n",
       " 1.8351024,\n",
       " 1.1051787,\n",
       " 1.2382519,\n",
       " 1.3485203,\n",
       " 1.068236,\n",
       " 1.3878156,\n",
       " 2.5479057,\n",
       " 1.1893694,\n",
       " 1.3599553,\n",
       " 1.141477,\n",
       " 1.1682338,\n",
       " 1.4910094,\n",
       " 1.7961316,\n",
       " 0.9684146,\n",
       " 1.4487875,\n",
       " 1.4625648,\n",
       " 1.1866661,\n",
       " 1.9511265,\n",
       " 1.2429385,\n",
       " 1.8182157,\n",
       " 1.4405912,\n",
       " 1.3152164,\n",
       " 1.6484393,\n",
       " 1.4894464,\n",
       " 2.1846595,\n",
       " 2.3402557,\n",
       " 1.9393164,\n",
       " 1.4537195,\n",
       " 1.4072042,\n",
       " 1.4026803,\n",
       " 1.324041,\n",
       " 1.1162521,\n",
       " 3.088904,\n",
       " 2.093707,\n",
       " 1.699683,\n",
       " 1.2451279,\n",
       " 1.4648932,\n",
       " 1.6001402,\n",
       " 1.3581135,\n",
       " 1.2249688,\n",
       " 1.775923,\n",
       " 1.9776484,\n",
       " 1.4034181,\n",
       " 1.6829048,\n",
       " 1.41499,\n",
       " 1.2540215,\n",
       " 1.4578062,\n",
       " 1.4116453,\n",
       " 1.338535,\n",
       " 2.7565475,\n",
       " 2.4065585,\n",
       " 2.0454793,\n",
       " 1.4832513,\n",
       " 1.1798767,\n",
       " 1.3239974,\n",
       " 1.7079974,\n",
       " 1.8372446,\n",
       " 1.2341883,\n",
       " 1.562606,\n",
       " 1.2466354,\n",
       " 1.796942,\n",
       " 1.4931158,\n",
       " 1.0500921,\n",
       " 1.463157,\n",
       " 1.1609966,\n",
       " 1.0613042,\n",
       " 1.8097843,\n",
       " 3.0316405,\n",
       " 1.694141,\n",
       " 1.3266408,\n",
       " 1.2208648,\n",
       " 1.5809804,\n",
       " 3.117755,\n",
       " 1.3919585,\n",
       " 1.2357391,\n",
       " 1.8488292,\n",
       " 1.2440828,\n",
       " 2.7559962,\n",
       " 3.399482,\n",
       " 1.1739634,\n",
       " 1.4164499,\n",
       " 1.8712442,\n",
       " 1.351243,\n",
       " 1.5989331,\n",
       " 1.231376,\n",
       " 2.5687923,\n",
       " 1.9731753,\n",
       " 1.2740759,\n",
       " 1.7063524,\n",
       " 1.2796001,\n",
       " 1.0443853,\n",
       " 1.9121321,\n",
       " 1.0900965,\n",
       " 1.4600842,\n",
       " 1.423435,\n",
       " 1.2715486,\n",
       " 3.8603148,\n",
       " 1.1966035,\n",
       " 1.69714,\n",
       " 1.780947,\n",
       " 2.331232,\n",
       " 1.6740304,\n",
       " 3.5982916,\n",
       " 2.9318075,\n",
       " 2.42278,\n",
       " 2.914582,\n",
       " 1.1990834,\n",
       " 1.5335752,\n",
       " 1.1293095,\n",
       " 0.9369793,\n",
       " 2.7914898,\n",
       " 1.4252684,\n",
       " 1.2354031,\n",
       " 1.3332636,\n",
       " 1.9648625,\n",
       " 2.2023935,\n",
       " 1.123328,\n",
       " 1.828806,\n",
       " 1.7910923,\n",
       " 1.2675885,\n",
       " 2.2492056,\n",
       " 2.2630105,\n",
       " 1.0997152,\n",
       " 0.8603218,\n",
       " 2.0463588,\n",
       " 1.6281122,\n",
       " 1.357742,\n",
       " 3.279896,\n",
       " 1.6713449,\n",
       " 2.243133,\n",
       " 2.3910162,\n",
       " 1.1650562,\n",
       " 1.308064,\n",
       " 2.0171185,\n",
       " 2.8919196,\n",
       " 1.3894866,\n",
       " 1.3474623,\n",
       " 1.2670529,\n",
       " 1.6573585,\n",
       " 1.2649733,\n",
       " 0.9923192,\n",
       " 1.4543751,\n",
       " 1.8353385,\n",
       " 1.1784319,\n",
       " 1.2094417,\n",
       " 1.647199,\n",
       " 1.8096724,\n",
       " 2.0421069,\n",
       " 1.974131,\n",
       " 1.0955465,\n",
       " 1.0931158,\n",
       " 0.9377093,\n",
       " 1.4780759,\n",
       " 0.80147,\n",
       " 1.4682242,\n",
       " 1.3507622,\n",
       " 1.9490106,\n",
       " 1.3298444,\n",
       " 1.4258049,\n",
       " 2.1428277,\n",
       " 1.5259638,\n",
       " 1.4428201,\n",
       " 1.7171015,\n",
       " 1.2256618,\n",
       " 1.0749797,\n",
       " 1.3225368,\n",
       " 1.1804391,\n",
       " 1.3994493,\n",
       " 1.8889061,\n",
       " 1.3621144,\n",
       " 1.9260403,\n",
       " 2.8779218,\n",
       " 2.3227632,\n",
       " 1.1970632,\n",
       " 1.1624652,\n",
       " 1.9077619,\n",
       " 2.6147504,\n",
       " 1.2519914,\n",
       " 2.410699,\n",
       " 1.1670275,\n",
       " 1.430091,\n",
       " 1.1513684,\n",
       " 2.9489043,\n",
       " 1.423626,\n",
       " 1.1991004,\n",
       " 1.0377121,\n",
       " 1.0243254,\n",
       " 1.300254,\n",
       " 1.8445487,\n",
       " 1.7378175,\n",
       " 2.1222665,\n",
       " 0.8052762,\n",
       " 1.5692598,\n",
       " 1.8281049,\n",
       " 1.8086107,\n",
       " 1.21565,\n",
       " 1.2515639,\n",
       " 1.290964,\n",
       " 1.5461574,\n",
       " 1.5904564,\n",
       " 2.3175702,\n",
       " 1.5846893,\n",
       " 3.4017158,\n",
       " 1.6663623,\n",
       " 1.8792795,\n",
       " 1.2087784,\n",
       " 1.9302579,\n",
       " 2.802868,\n",
       " 1.5392723,\n",
       " 1.71817,\n",
       " 1.3870741,\n",
       " 1.1222297,\n",
       " 1.9298506,\n",
       " 1.666809,\n",
       " 1.6252652,\n",
       " 2.1106942,\n",
       " 1.2294424,\n",
       " 1.1963977,\n",
       " 1.3557094,\n",
       " 1.5214866,\n",
       " 1.4089473,\n",
       " 1.2512558,\n",
       " 1.5691191,\n",
       " 1.3622779,\n",
       " 2.2942107,\n",
       " 1.2491944,\n",
       " 1.303183,\n",
       " 1.2884742,\n",
       " 2.3262374,\n",
       " 1.3591075,\n",
       " 2.3307822,\n",
       " 2.0593643,\n",
       " 1.2507874,\n",
       " 2.6742053,\n",
       " 1.5735575,\n",
       " 1.1004628,\n",
       " 0.86999756,\n",
       " 1.6929284,\n",
       " 1.2177774,\n",
       " 2.0283115,\n",
       " 1.2443672,\n",
       " 1.2907565,\n",
       " 1.2731305,\n",
       " 1.2838281,\n",
       " 1.3705958,\n",
       " 1.9303917,\n",
       " 1.708506,\n",
       " 1.1425725,\n",
       " 2.1709018,\n",
       " 1.296933,\n",
       " 3.3803132,\n",
       " 1.3663623,\n",
       " 1.5444795,\n",
       " 1.4878553,\n",
       " 1.2980484,\n",
       " 1.3174243,\n",
       " 1.428006,\n",
       " 1.2284042,\n",
       " 2.1572816,\n",
       " 2.1580634,\n",
       " 1.612837,\n",
       " 3.3198237,\n",
       " 1.3451751,\n",
       " 1.7004312,\n",
       " 1.7703849,\n",
       " 1.0765345,\n",
       " 1.7443923,\n",
       " 1.2912569,\n",
       " 1.0715258,\n",
       " 1.1999624,\n",
       " 1.5167744,\n",
       " 2.0017881,\n",
       " 2.4942663,\n",
       " 1.9687414,\n",
       " 1.6261101,\n",
       " 2.0860522,\n",
       " 1.1717838,\n",
       " 1.1567739,\n",
       " 1.2837346,\n",
       " 1.925362,\n",
       " 2.104235,\n",
       " 1.1428328,\n",
       " 2.0486434,\n",
       " 2.8156896,\n",
       " 1.2715355,\n",
       " 1.2801384,\n",
       " 1.2604688,\n",
       " 1.2477258,\n",
       " 1.2319177,\n",
       " 1.3420738,\n",
       " 0.88442165,\n",
       " 1.2639927,\n",
       " 0.8107366,\n",
       " 1.6767775,\n",
       " 3.4085836,\n",
       " 1.050759,\n",
       " 1.4221534,\n",
       " 1.777082,\n",
       " 1.6917464,\n",
       " 2.3765182,\n",
       " 0.78643817,\n",
       " 1.1339709,\n",
       " 1.3064061,\n",
       " 1.3776417,\n",
       " 1.6866655,\n",
       " 1.4551517,\n",
       " 0.75567824,\n",
       " 1.3192593,\n",
       " 0.8224308,\n",
       " 1.4927255,\n",
       " 2.1939611,\n",
       " 2.4661207,\n",
       " 1.2025251,\n",
       " 3.6063538,\n",
       " 1.6378546,\n",
       " 1.2883097,\n",
       " 1.4002333,\n",
       " 0.84427446,\n",
       " 1.2774084,\n",
       " 2.2377713,\n",
       " 2.1665444,\n",
       " 1.4354289,\n",
       " 1.8954618,\n",
       " 1.5603487,\n",
       " 1.3347708,\n",
       " 2.6439967,\n",
       " 1.105351,\n",
       " 1.2664535,\n",
       " 1.538837,\n",
       " 1.1461469,\n",
       " 1.9572204,\n",
       " 2.1690993,\n",
       " 1.1557754,\n",
       " 1.1310333,\n",
       " 1.7466395,\n",
       " 1.8779197,\n",
       " 1.0949878,\n",
       " 1.8756413,\n",
       " 1.1849478,\n",
       " 1.0198672,\n",
       " 2.439192,\n",
       " 1.609561,\n",
       " 0.95339435,\n",
       " 0.98013026,\n",
       " 1.3007207,\n",
       " 0.8860654,\n",
       " 2.0942943,\n",
       " 1.2419409,\n",
       " 1.4441894,\n",
       " 1.3209635,\n",
       " 1.2712916,\n",
       " 1.1094967,\n",
       " 2.7639227,\n",
       " 1.1585101,\n",
       " 1.5780106,\n",
       " 1.075467,\n",
       " 1.5381957,\n",
       " 1.3737506,\n",
       " 1.9399439,\n",
       " 1.4744123,\n",
       " 3.2628193,\n",
       " 0.91948515,\n",
       " 1.0078254,\n",
       " 1.5235709,\n",
       " 2.488077,\n",
       " 1.9693991,\n",
       " 1.9147474,\n",
       " 1.2191046,\n",
       " 1.087002,\n",
       " 1.5780519,\n",
       " 1.0691876,\n",
       " 1.3406909,\n",
       " 1.5002009,\n",
       " 1.4494035,\n",
       " 1.590954,\n",
       " 1.9556961,\n",
       " 2.2528477,\n",
       " 3.5380707,\n",
       " 1.5972203,\n",
       " 1.2162001,\n",
       " 1.829146,\n",
       " 1.2525612,\n",
       " 1.4591491,\n",
       " 1.7465166,\n",
       " 2.3858738,\n",
       " 1.6732999,\n",
       " 1.3107617,\n",
       " 1.184758,\n",
       " 1.9408509,\n",
       " 1.2442898,\n",
       " 2.6570275,\n",
       " 1.2327949,\n",
       " 1.2672956,\n",
       " 1.1848705,\n",
       " 1.8799367,\n",
       " 2.0368812,\n",
       " 2.163234,\n",
       " 1.5775293,\n",
       " 1.1171013,\n",
       " 1.0266994,\n",
       " 0.9647712,\n",
       " 1.77896,\n",
       " 2.7115006,\n",
       " 1.6702927,\n",
       " 0.94271713,\n",
       " 1.1648095,\n",
       " 2.1163726,\n",
       " 1.1483011,\n",
       " 1.602605,\n",
       " 3.0903368,\n",
       " 1.3509774,\n",
       " 1.4140364,\n",
       " 1.257559,\n",
       " 2.3465667,\n",
       " 3.3909492,\n",
       " 2.2217696,\n",
       " 1.9803404,\n",
       " 1.0072298,\n",
       " 1.5808328,\n",
       " 2.0462818,\n",
       " 2.4340904,\n",
       " 2.0128849,\n",
       " 1.99842,\n",
       " 1.6524518,\n",
       " 1.7138634,\n",
       " 1.2116905,\n",
       " 1.1986207,\n",
       " 1.8436179,\n",
       " 1.7306234,\n",
       " 1.3350602,\n",
       " 1.6511015,\n",
       " 1.1163989,\n",
       " 2.0227907,\n",
       " 1.2733326,\n",
       " 1.2981526,\n",
       " 1.1850172,\n",
       " 1.4386305,\n",
       " 1.0816265,\n",
       " 1.1831609,\n",
       " 2.5685267,\n",
       " 1.4163498,\n",
       " 1.5657403,\n",
       " 1.2142483,\n",
       " 1.4750228,\n",
       " 1.1291434,\n",
       " 1.2816921,\n",
       " 1.1554421,\n",
       " 2.1560485,\n",
       " 1.2808954,\n",
       " 3.728965,\n",
       " 2.0056088,\n",
       " 1.2950982,\n",
       " 1.8358935,\n",
       " 1.3297794,\n",
       " 2.3251266,\n",
       " 1.526627,\n",
       " 2.0039425,\n",
       " 0.9405733,\n",
       " 1.0722593,\n",
       " 1.4207695,\n",
       " 3.7716608,\n",
       " 1.9314775,\n",
       " 1.1516,\n",
       " 1.0522829,\n",
       " 1.0672307,\n",
       " 1.530208,\n",
       " 1.6388125,\n",
       " 1.129733,\n",
       " 1.5421215,\n",
       " 1.1703169,\n",
       " 1.1585711,\n",
       " 1.2380533,\n",
       " 1.3905529,\n",
       " 2.949201,\n",
       " 1.2065829,\n",
       " 1.4642131,\n",
       " 1.3645682,\n",
       " 1.4625381,\n",
       " 1.1028354,\n",
       " 1.4061841,\n",
       " 2.3279033,\n",
       " 1.5661608,\n",
       " 2.06321,\n",
       " 1.257981,\n",
       " 1.9200987,\n",
       " 1.4595311,\n",
       " 2.2911515,\n",
       " 1.6577648,\n",
       " 1.2747904,\n",
       " 1.2274128,\n",
       " 2.486037,\n",
       " 1.2533523,\n",
       " 1.4359708,\n",
       " 1.0895365,\n",
       " 1.7830118,\n",
       " 1.625796,\n",
       " 2.870503,\n",
       " 1.3359182,\n",
       " 1.1708809,\n",
       " 1.2065738,\n",
       " 2.8801937,\n",
       " 1.5443083,\n",
       " 1.3154494,\n",
       " 1.5747517,\n",
       " 2.1350508,\n",
       " 1.193722,\n",
       " 1.3373772,\n",
       " 1.5205353,\n",
       " 1.573386,\n",
       " 3.6482966,\n",
       " 2.4445753,\n",
       " 0.9494893,\n",
       " 1.1981696,\n",
       " 1.073851,\n",
       " 1.9844917,\n",
       " 1.2658428,\n",
       " 1.5254872,\n",
       " 2.223841,\n",
       " 1.1340401,\n",
       " 1.0151135,\n",
       " 1.1687735,\n",
       " 3.7190707,\n",
       " 1.3562672,\n",
       " 1.1955833,\n",
       " 1.3614583,\n",
       " 1.0661014,\n",
       " 1.1996939,\n",
       " 1.0783736,\n",
       " 1.743037,\n",
       " 1.3082052,\n",
       " 2.293749,\n",
       " 1.0716524,\n",
       " 1.468941,\n",
       " 1.2525373,\n",
       " 2.1133466,\n",
       " 1.6182836,\n",
       " 1.5891026,\n",
       " 1.5223342,\n",
       " 1.176776,\n",
       " 1.6007313,\n",
       " 1.2281092,\n",
       " 1.1357709,\n",
       " 1.2542936,\n",
       " 1.6030625,\n",
       " 1.2697575,\n",
       " 1.6440811,\n",
       " 1.3636976,\n",
       " 1.3396661,\n",
       " 3.0369537,\n",
       " 1.0673878,\n",
       " 1.6438586,\n",
       " 2.4081073,\n",
       " 1.5194691,\n",
       " 1.3348557,\n",
       " 1.1245617,\n",
       " 1.5620297,\n",
       " 1.6039395,\n",
       " 1.7381681,\n",
       " 1.7782056,\n",
       " 2.0503142,\n",
       " 1.4888514,\n",
       " 1.6630564,\n",
       " 1.3679663,\n",
       " 2.0602438,\n",
       " 0.96177346,\n",
       " 5.0457754,\n",
       " 2.9042118,\n",
       " 0.9228249,\n",
       " 1.571049,\n",
       " 1.0661645,\n",
       " 1.6015315,\n",
       " 4.103262,\n",
       " 2.0405245,\n",
       " 1.2452246,\n",
       " 1.288022,\n",
       " 1.9978558,\n",
       " 1.3483821,\n",
       " 1.4236721,\n",
       " 1.2998046,\n",
       " 2.3728168,\n",
       " 0.95727676,\n",
       " 1.557214,\n",
       " 1.7562506,\n",
       " 1.6837002,\n",
       " 2.1420376,\n",
       " 0.9058351,\n",
       " 1.745105,\n",
       " 1.8985056,\n",
       " 1.5423905,\n",
       " 1.2567098,\n",
       " 1.1018869,\n",
       " 1.114086,\n",
       " 1.4294146,\n",
       " 1.8191408,\n",
       " 1.5883495,\n",
       " 1.3235725,\n",
       " 1.1794357,\n",
       " 1.2706184,\n",
       " 1.5890206,\n",
       " 1.6564195,\n",
       " 1.7650654,\n",
       " 1.7641097,\n",
       " 0.7310591,\n",
       " 1.7071463,\n",
       " 1.573984,\n",
       " 2.6719189,\n",
       " 2.2944994,\n",
       " 1.2211593,\n",
       " 2.2670445,\n",
       " 1.576567,\n",
       " 1.4649523,\n",
       " 2.5946147,\n",
       " 1.8728408,\n",
       " 1.4630493,\n",
       " 0.9497486,\n",
       " 1.4615663,\n",
       " 1.429709,\n",
       " 1.3892179,\n",
       " 1.5986121,\n",
       " 1.2103684,\n",
       " 1.2587262,\n",
       " 2.2534122,\n",
       " 2.3885655,\n",
       " 1.759895,\n",
       " 2.2475138,\n",
       " 1.2422823,\n",
       " 1.5520858,\n",
       " 1.8006735,\n",
       " 2.9956753,\n",
       " 1.7284939,\n",
       " 1.2937568,\n",
       " 3.9926596,\n",
       " 1.024118,\n",
       " 1.0257828,\n",
       " 1.5619956,\n",
       " 2.0558825,\n",
       " 1.1647569,\n",
       " 1.2697965,\n",
       " 3.005205,\n",
       " 1.0262429,\n",
       " 0.9194151,\n",
       " 2.000073,\n",
       " 2.3042884,\n",
       " 1.6292671,\n",
       " 2.0278192,\n",
       " 1.1792891,\n",
       " 1.0144393,\n",
       " 1.1291336,\n",
       " 1.2988275,\n",
       " 1.3102877,\n",
       " 0.8973667,\n",
       " 1.5397531,\n",
       " 1.4684048,\n",
       " 0.9275097,\n",
       " 1.0241462,\n",
       " 1.4684763,\n",
       " 2.552322,\n",
       " 1.3586301,\n",
       " 1.5720528,\n",
       " 1.2555447,\n",
       " 1.0786572,\n",
       " 1.1630731,\n",
       " 1.6416566,\n",
       " 1.034239,\n",
       " 2.2592692,\n",
       " 1.6886252,\n",
       " 1.9593428,\n",
       " 0.8098145,\n",
       " 1.6372448,\n",
       " 1.7553818,\n",
       " 1.3913263,\n",
       " 2.4595158,\n",
       " 2.2375216,\n",
       " 1.126629,\n",
       " 1.5506186,\n",
       " 1.2698323,\n",
       " 1.3339713,\n",
       " 1.4339479,\n",
       " 1.7169131,\n",
       " 1.1838927,\n",
       " 1.4609772,\n",
       " 1.6008497,\n",
       " 1.1890535,\n",
       " 1.4551711,\n",
       " 2.1563299,\n",
       " 2.475914,\n",
       " 1.3599745,\n",
       " 0.9462658,\n",
       " 1.4772168,\n",
       " 1.4480022,\n",
       " 1.3551209,\n",
       " 1.3239108,\n",
       " 2.1195018,\n",
       " 0.92924446,\n",
       " 0.87194186,\n",
       " 1.1400707,\n",
       " 1.2530985,\n",
       " 1.5170566,\n",
       " 1.4679304,\n",
       " 1.9640726,\n",
       " 1.9530967,\n",
       " 1.2941531,\n",
       " 1.1327306,\n",
       " 1.9279842,\n",
       " 0.7989004,\n",
       " 1.6848814,\n",
       " 1.2318045,\n",
       " 1.7838947,\n",
       " 1.6416763,\n",
       " 1.4980339,\n",
       " 1.6876782,\n",
       " 2.271941,\n",
       " 1.7443016,\n",
       " 1.8207217,\n",
       " 1.1332735,\n",
       " 1.1891398,\n",
       " 1.3318024,\n",
       " 1.3329352,\n",
       " 0.85877335,\n",
       " 2.4262278,\n",
       " 2.5340955,\n",
       " 1.1885608,\n",
       " 2.7112913,\n",
       " 1.1546015,\n",
       " 1.0164925,\n",
       " 2.1207602,\n",
       " 2.1061618,\n",
       " 1.5626115,\n",
       " 1.0896052,\n",
       " 2.0548491,\n",
       " 0.9873133,\n",
       " 2.2191806,\n",
       " 2.9969683,\n",
       " 1.1468278,\n",
       " 1.1441487,\n",
       " 1.3154733,\n",
       " 0.96452695,\n",
       " 2.7515497,\n",
       " 1.4774941,\n",
       " 0.9747742,\n",
       " 1.6253082,\n",
       " 2.117398,\n",
       " 0.9609321,\n",
       " 1.7212862,\n",
       " 1.790861,\n",
       " 1.3874943,\n",
       " 1.5595534,\n",
       " 1.4489559,\n",
       " 2.3927608,\n",
       " 4.3242927,\n",
       " 2.8133547,\n",
       " 1.2481776,\n",
       " 1.5236816,\n",
       " 1.279014,\n",
       " 1.5692369,\n",
       " 1.3639734,\n",
       " 1.2721907,\n",
       " 1.4401932,\n",
       " 1.8942808,\n",
       " 2.2160342,\n",
       " 2.3513086,\n",
       " 1.0706632,\n",
       " 1.3200129,\n",
       " 1.466709,\n",
       " 2.3198714,\n",
       " 1.189553,\n",
       " 1.6807109,\n",
       " 1.5359644,\n",
       " 1.9509519,\n",
       " 1.526304,\n",
       " 1.4759036,\n",
       " 1.3237712,\n",
       " 1.366126,\n",
       " 1.6746565,\n",
       " 1.4930928,\n",
       " 1.5167946,\n",
       " 1.7255386,\n",
       " 1.7041568,\n",
       " 1.9480381,\n",
       " 1.053801,\n",
       " 1.3884591,\n",
       " 1.1728132,\n",
       " 2.0143967,\n",
       " 1.0433601,\n",
       " 2.392273,\n",
       " 1.2883072,\n",
       " 2.4194605,\n",
       " 1.0756572,\n",
       " 1.6981895,\n",
       " 2.0993595,\n",
       " 2.3841965,\n",
       " 2.422032,\n",
       " 1.2518636,\n",
       " 1.9597954,\n",
       " 1.7323805,\n",
       " 1.5460547,\n",
       " 1.2486933,\n",
       " 1.2951086,\n",
       " 1.5090241,\n",
       " 1.651861,\n",
       " 1.5273813,\n",
       " 2.4510753,\n",
       " 1.3154703,\n",
       " 1.6422812,\n",
       " 1.6439096,\n",
       " 1.3017453,\n",
       " 1.2902383,\n",
       " 2.6999938,\n",
       " 1.9747583,\n",
       " 1.6787755,\n",
       " 1.3170229,\n",
       " 1.2015575,\n",
       " 2.4899793,\n",
       " 1.8638502,\n",
       " 1.6177787,\n",
       " 1.1000631,\n",
       " 1.6408736,\n",
       " 2.697815,\n",
       " 1.051516,\n",
       " 1.2180157,\n",
       " 1.560414,\n",
       " 1.5851443,\n",
       " 2.387208,\n",
       " 1.3210517,\n",
       " 1.8451109,\n",
       " 1.6086936,\n",
       " 1.9677736,\n",
       " 4.0083766,\n",
       " 1.3520828,\n",
       " 1.396782,\n",
       " 2.106968,\n",
       " 1.6402321,\n",
       " 1.3402349,\n",
       " 2.1722598,\n",
       " 1.6784772,\n",
       " 1.5205564,\n",
       " 1.1944227,\n",
       " 1.230727,\n",
       " 1.5841935,\n",
       " 3.7147145,\n",
       " 1.202336,\n",
       " 1.2884388,\n",
       " 1.4663446,\n",
       " 1.4854707,\n",
       " 1.1096611,\n",
       " 0.8880491,\n",
       " 1.4841188,\n",
       " 1.6241981,\n",
       " 1.2488769,\n",
       " 1.8289962,\n",
       " 1.8558886,\n",
       " 0.9885846,\n",
       " 1.1827209,\n",
       " 1.4992001,\n",
       " 1.3256589,\n",
       " 1.7355117,\n",
       " 1.2146666,\n",
       " 1.2413298,\n",
       " 1.7998945,\n",
       " 1.3758135,\n",
       " 2.6889558,\n",
       " 1.2341334,\n",
       " 1.1719364,\n",
       " 3.274964,\n",
       " 1.3754741,\n",
       " 1.5913218,\n",
       " 1.4875634,\n",
       " 1.3905588,\n",
       " 1.7994801,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicitons to csv file in the format\n",
    "# id,rating\n",
    "test_df[\"rating\"] = predictions\n",
    "test_df[[\"id\", \"rating\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVD...\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9273  0.9324  0.9262  0.9278  0.9306  0.9289  0.0023  \n",
      "Fit time          1.01    1.06    1.07    1.04    1.07    1.05    0.02    \n",
      "Test time         0.09    0.07    0.25    0.07    0.06    0.11    0.07    \n",
      "Evaluating KNNBasic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1397  1.1417  1.1437  1.1506  1.1429  1.1437  0.0037  \n",
      "Fit time          2.24    2.65    2.39    2.27    2.33    2.37    0.15    \n",
      "Test time         0.46    0.25    0.35    0.24    0.25    0.31    0.08    \n",
      "Evaluating KNNWithZScore...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0502  1.0518  1.0479  1.0450  1.0512  1.0492  0.0025  \n",
      "Fit time          2.48    2.69    2.63    2.73    2.70    2.65    0.09    \n",
      "Test time         0.26    0.27    0.26    0.29    0.41    0.30    0.06    \n",
      "Evaluating KNNBaseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0027  0.9977  1.0048  1.0013  1.0024  1.0018  0.0023  \n",
      "Fit time          2.40    2.65    2.64    2.51    2.57    2.56    0.09    \n",
      "Test time         0.56    0.25    0.39    0.39    0.24    0.37    0.12    \n",
      "Evaluating NMF...\n",
      "Evaluating RMSE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0529  1.0469  1.0571  1.0752  1.0565  1.0577  0.0095  \n",
      "Fit time          2.71    2.54    2.58    2.58    2.59    2.60    0.06    \n",
      "Test time         0.06    0.05    0.05    0.05    0.05    0.05    0.00    \n",
      "Evaluating SlopeOne...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from surprise import (\n",
    "    Dataset,\n",
    "    Reader,\n",
    "    SVD,\n",
    "    KNNBasic,\n",
    "    KNNWithMeans,\n",
    "    KNNWithZScore,\n",
    "    KNNBaseline,\n",
    "    NMF,\n",
    "    SlopeOne,\n",
    "    CoClustering,\n",
    "    BaselineOnly,\n",
    "    NormalPredictor,\n",
    ")\n",
    "from surprise.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "# List of models to test\n",
    "models = [\n",
    "    (\"SVD\", SVD()),\n",
    "    (\"KNNBasic\", KNNBasic()),\n",
    "    (\"KNNWithZScore\", KNNWithZScore()),\n",
    "    (\"KNNBaseline\", KNNBaseline()),\n",
    "    (\"NMF\", NMF()),\n",
    "    (\"CoClustering\", CoClustering()),\n",
    "    (\"BaselineOnly\", BaselineOnly()),\n",
    "    (\"NormalPredictor\", NormalPredictor()),\n",
    "]\n",
    "\n",
    "# Prepare the data\n",
    "reader = Reader(rating_scale=(train_df[\"rating\"].min(), train_df[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(train_df[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
    "\n",
    "# Iterate over models and cross-validate\n",
    "results = []\n",
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_results = cross_validate(model, data, measures=[\"RMSE\"], cv=5, verbose=True)\n",
    "    mean_rmse = cv_results[\"test_rmse\"].mean()\n",
    "    results.append((name, mean_rmse))\n",
    "\n",
    "# Sort models by RMSE\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Display the results\n",
    "for name, rmse in results:\n",
    "    print(f\"{name}: RMSE = {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
