{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Works with OpenLibrary API, we want to improve it with google books api'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Works with OpenLibrary API, we want to improve it with google books api\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/books_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  book_id\n",
       "0  0002005018        1\n",
       "1  0374157065        3\n",
       "2  0399135782        5\n",
       "3  0440234743       18\n",
       "4  0452264464       19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from requests import Session\n",
    "# from requests_ratelimiter import LimiterAdapter\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def fetch_book_data():\n",
    "#     # Set up rate-limited session\n",
    "#     session = Session()\n",
    "#     adapter = LimiterAdapter(per_second=5)  # Adjust rate limit as needed\n",
    "#     session.mount(\"https://openlibrary.org/\", adapter)\n",
    "    \n",
    "#     # Read input data\n",
    "#     books_df = pd.read_csv('../data/books.csv')\n",
    "    \n",
    "#     extended_data = []\n",
    "#     for isbn in tqdm(books_df['ISBN'], desc=\"Fetching book data\"):\n",
    "#         try:\n",
    "#             # Fetch book data\n",
    "#             response = session.get(f\"https://openlibrary.org/isbn/{isbn}.json\")\n",
    "#             if response.status_code == 200:\n",
    "#                 book_data = response.json()\n",
    "                \n",
    "#                 # Extract features\n",
    "#                 features = {\n",
    "#                     'ISBN': isbn,\n",
    "#                     'number_of_pages': book_data.get('number_of_pages'),\n",
    "#                     'genres': ','.join(book_data.get('genres', [])),\n",
    "#                     'publish_date': book_data.get('publish_date'),\n",
    "#                     'authors': ','.join([author.get('key', '') for author in book_data.get('authors', [])]),\n",
    "#                     'publishers': ','.join(book_data.get('publishers', [])),\n",
    "#                     'languages': ','.join([language.get('key', '') for language in book_data.get('languages', [])]),\n",
    "#                     'subjects': ','.join(book_data.get('subjects', []))\n",
    "#                 }\n",
    "#                 extended_data.append(features)\n",
    "#             else:\n",
    "#                 extended_data.append({'ISBN': isbn})\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with ISBN {isbn}: {e}\")\n",
    "#             extended_data.append({'ISBN': isbn})\n",
    "    \n",
    "#     extended_df = pd.DataFrame(extended_data)\n",
    "#     books_df = books_df.merge(extended_df, on='ISBN', how='left')\n",
    "#     books_df.to_csv('../data/extended_books.csv', index=False)\n",
    "#     print(\"Extended dataset created and saved.\")\n",
    "    \n",
    "#     session.close()\n",
    "\n",
    "# fetch_book_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching book data: 100%|██████████| 16599/16599 [4:31:38<00:00,  1.02it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended dataset created and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests import Session\n",
    "from requests_ratelimiter import LimiterAdapter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fetch_author_name(session, author_key):\n",
    "    author_url = f\"https://openlibrary.org{author_key}.json\"\n",
    "    response = session.get(author_url)\n",
    "    if response.status_code == 200:\n",
    "        author_data = response.json()\n",
    "        return author_data.get('name')\n",
    "    return None\n",
    "\n",
    "def fetch_book_data():\n",
    "    session = Session()\n",
    "    adapter = LimiterAdapter(per_second=5)\n",
    "    session.mount(\"https://openlibrary.org/\", adapter)\n",
    "\n",
    "    books_df = pd.read_csv('../data/books_fixed.csv')\n",
    "    \n",
    "    extended_data = []\n",
    "    for isbn in tqdm(books_df['ISBN'], desc=\"Fetching book data\"):\n",
    "        try:\n",
    "            response = session.get(f\"https://openlibrary.org/isbn/{isbn}.json\")\n",
    "            if response.status_code == 200:\n",
    "                book_data = response.json()\n",
    "                \n",
    "                authors = [fetch_author_name(session, author.get('key')) for author in book_data.get('authors', [])]\n",
    "                \n",
    "                features = {\n",
    "                    'ISBN': isbn,\n",
    "                    'number_of_pages': book_data.get('number_of_pages'),\n",
    "                    'genres': ','.join(book_data.get('genres', [])),\n",
    "                    'publish_date': book_data.get('publish_date'),\n",
    "                    'authors': ','.join(filter(None, authors)),  # Join only non-None authors\n",
    "                    'publishers': ','.join(book_data.get('publishers', [])),\n",
    "                    'languages': ','.join([language.get('key', '').replace('/languages/', '') for language in book_data.get('languages', [])]),\n",
    "                    'subjects': ','.join(book_data.get('subjects', []))\n",
    "                }\n",
    "                extended_data.append(features)\n",
    "            else:\n",
    "                extended_data.append({'ISBN': isbn})\n",
    "        except Exception as e:\n",
    "            print(f\"Error with ISBN {isbn}: {e}\")\n",
    "            extended_data.append({'ISBN': isbn})\n",
    "    \n",
    "    extended_df = pd.DataFrame(extended_data)\n",
    "    books_df = books_df.merge(extended_df, on='ISBN', how='left')\n",
    "    books_df.to_csv('../data/extended_books_openlibrary.csv', index=False)\n",
    "    print(\"Extended dataset created and saved.\")\n",
    "    \n",
    "    session.close()\n",
    "\n",
    "fetch_book_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching book data:   0%|          | 0/16599 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching book data:  25%|██▌       | 4210/16599 [1:01:22<3:00:21,  1.14it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests import Session\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "def fetch_book_data_google():\n",
    "    session = Session()\n",
    "    books_df = pd.read_csv('../data/books_fixed.csv')\n",
    "    \n",
    "    extended_books_path = '../data/extended_books_google.csv'\n",
    "    if os.path.exists(extended_books_path):\n",
    "        extended_books_df = pd.read_csv(extended_books_path)\n",
    "        fetched_isbns = set(extended_books_df['ISBN'].dropna())\n",
    "    else:\n",
    "        extended_books_df = pd.DataFrame()\n",
    "        fetched_isbns = set()\n",
    "    \n",
    "    new_isbns = books_df[~books_df['ISBN'].isin(fetched_isbns)]['ISBN']\n",
    "    \n",
    "    extended_data = []\n",
    "    for isbn in tqdm(new_isbns, desc=\"Fetching book data\"):\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            response = session.get(f\"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}\")\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                if results['totalItems'] > 0:\n",
    "                    book_data = results['items'][0]['volumeInfo']\n",
    "                    \n",
    "                    # Extract relevant information\n",
    "                    features = {\n",
    "                        'ISBN': isbn,\n",
    "                        'title': book_data.get('title'),\n",
    "                        'subtitle': book_data.get('subtitle'),\n",
    "                        'authors': ','.join(book_data.get('authors', [])),\n",
    "                        'publisher': book_data.get('publisher'),\n",
    "                        'publishedDate': book_data.get('publishedDate'),\n",
    "                        'description': book_data.get('description'),\n",
    "                        'pageCount': book_data.get('pageCount'),\n",
    "                        'maturityRating': book_data.get('maturityRating'),\n",
    "                        'language': book_data.get('language'),\n",
    "                        'categories': ','.join(book_data.get('categories', [])),\n",
    "                        'ratingsCount': book_data.get('ratingsCount'),\n",
    "                        'averageRating': book_data.get('averageRating'),\n",
    "                        'textSnippet': book_data.get('searchInfo', {}).get('textSnippet')\n",
    "                    }\n",
    "                    extended_data.append(features)\n",
    "                else:\n",
    "                    extended_data.append({'ISBN': isbn})\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for ISBN {isbn}\")\n",
    "                extended_data.append({'ISBN': isbn})\n",
    "        except Exception as e:\n",
    "            print(f\"Error with ISBN {isbn}: {e}\")\n",
    "            extended_data.append({'ISBN': isbn})\n",
    "    \n",
    "    new_extended_df = pd.DataFrame(extended_data)\n",
    "    \n",
    "    if not extended_books_df.empty:\n",
    "        combined_df = pd.concat([extended_books_df, new_extended_df], ignore_index=True)\n",
    "    else:\n",
    "        combined_df = new_extended_df\n",
    "    \n",
    "    combined_df.to_csv(extended_books_path, index=False)\n",
    "    print(\"Extended dataset created and saved with Google Books API.\")\n",
    "    \n",
    "    session.close()\n",
    "\n",
    "fetch_book_data_google()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
